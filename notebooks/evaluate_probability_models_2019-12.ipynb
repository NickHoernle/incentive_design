{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>\n",
       "code_show=true; \n",
       "function code_toggle() {\n",
       " if (code_show){\n",
       " $('div.input').hide();\n",
       " } else {\n",
       " $('div.input').show();\n",
       " }\n",
       " code_show = !code_show\n",
       "} \n",
       "$( document ).ready(code_toggle);\n",
       "</script>\n",
       "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the raw code.\"></form>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML('''<script>\n",
    "code_show=true; \n",
    "function code_toggle() {\n",
    " if (code_show){\n",
    " $('div.input').hide();\n",
    " } else {\n",
    " $('div.input').show();\n",
    " }\n",
    " code_show = !code_show\n",
    "} \n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the raw code.\"></form>''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('../src/'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.backends import cudnn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from tqdm import tqdm\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import load_so_data as so_data\n",
    "import main as explor\n",
    "import models\n",
    "# import utils\n",
    "import main\n",
    "\n",
    "import importlib as imp\n",
    "imp.reload(models)\n",
    "# imp.reload(utils)\n",
    "imp.reload(main)\n",
    "imp.reload(so_data)\n",
    "# Define data root directory\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "params = {'batch_size': 256, 'shuffle': True, 'num_workers': 6}\n",
    "max_epochs = 25\n",
    "\n",
    "# CUDA for PyTorch\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "cudnn.benchmark = True\n",
    "\n",
    "window_len = 5*7\n",
    "\n",
    "common_params = {\n",
    "    'window_length': window_len,\n",
    "    'badge_focus': 'Electorate',\n",
    "    'out_dim': 'QuestionVotes',\n",
    "    'data_path': '../data',\n",
    "#     'input_length': 4*7\n",
    "}\n",
    "\n",
    "dset_train = so_data.StackOverflowDataset(dset_type='train', subsample=4000, \n",
    "                                             **common_params)\n",
    "dset_test = so_data.StackOverflowDataset(dset_type='test', subsample=1000, \n",
    "                                             **common_params)\n",
    "dset_valid = so_data.StackOverflowDataset(dset_type='validate', subsample=1000, centered=True,\n",
    "                                             **common_params)\n",
    "\n",
    "train_loader = DataLoader(dset_train, **params)\n",
    "test_loader = DataLoader(dset_test, **params)\n",
    "valid_loader = DataLoader(dset_valid, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_loader.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Motivation\n",
    "\n",
    "We extend the theoretical model from <b>Anderson et al. (2013), Steering User Behavior with Badges</b> to a model that is grounded in the users' behaviour on Stack Overflow. From the model, we gain insights about how people act in the presence of a badge and how they repond to badge incentives.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Original model:**\n",
    "\n",
    "$$\n",
    "U(x_a) = \\sum\\limits_{b \\in B} I_b(a) V_b + \\theta \\sum\\limits_{i=1}^{n+1}x_a^i \\cdot U(x_{a+e_i}) - g(x_a, \\mathbf{p}) \n",
    "$$\n",
    "\n",
    "The probability of acting depends on:\n",
    "\n",
    "1. The user specific base distribution ($\\mathbf{p}$).\n",
    "2. The value of a badge (not specified if this is user specific or assumed external to the user) ($V_b$).\n",
    "3. The cost that a user pays for deviating from the base distribution ($g$).\n",
    "4. (some discount parameter $\\theta$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "s = np.concatenate([seq.numpy() for seq, kernel, out, prox, badge_date in train_loader], axis=0)\n",
    "o = np.concatenate([out.numpy() for seq, kernel, out, prox, badge_date in train_loader], axis=0)\n",
    "\n",
    "plt.figure(figsize=(15,4))\n",
    "# plt.plot(np.arange(-5*7, 5*7), np.mean(s[:,:,5], axis=0))\n",
    "plt.plot(np.arange(-5*7, 5*7), np.mean(o, axis=0))\n",
    "plt.axvline(0, c='red')\n",
    "plt.title('Mean Q-voting presence leading to Electorate Badge')\n",
    "plt.xlabel('Days before/after badge')\n",
    "plt.ylabel('Probability of Q-Vote')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Express as a graphical model \n",
    "\n",
    "- A user will only deviate if the badge value outweighs the cost of changing his/her default behaviour.\n",
    "\n",
    "- It follows that (2) and (3) can be understood as a deviation from the user's base distribution as the user approaches the badge boundary. This deviation is non-negative before the badge is achieved and non-positive after the badge has been achieved.\n",
    "\n",
    "- **A simplifying assumption:** the ''badge deviation'' (called kernel from now on) is a function that depends on the user's proximity to the badge and is a shared response between all users. This assumption can be relaxed at a later stage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Express as a graphical model \n",
    "\n",
    "We obtain the following graphical model for a user's interaction behaviour (p is the base distribution local to a user and $\\beta$ is the badge kernel:\n",
    "\n",
    "![img1](images/img1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "###  Address Weaknesses of baseline model:\n",
    "\n",
    "There is evidence that users do not respond uniformly to the badge. **Solution**: add a user-specific parameter that controls the strength of the effect of the badge response (shown below). $S \\in (0,1)$ is the parameter that controls the strenth of a user's adherence to the kernel. P and S are both local latent variables, specific to each user.  \n",
    "\n",
    "![img2](images/img2.png)\n",
    "\n",
    "**Note:** It is possible that users do not respond with the same functional form to a badge (not addressed yet)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "proximity = []\n",
    "s = []\n",
    "for seq, kernel, out, prox, badge_date in train_loader:\n",
    "    s.append(seq.numpy())\n",
    "    proximity.append(prox.numpy())\n",
    "    \n",
    "proximity = np.concatenate(proximity, axis=0)\n",
    "s = np.concatenate(s, axis=0)\n",
    "\n",
    "s.shape, proximity.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(15,5))\n",
    "# plt.hist(proximity[:,5*7], bins=50)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Brief motivation for strength parameter (S):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3,7, figsize=(15,7))\n",
    "\n",
    "date = 0\n",
    "for i in range(7):\n",
    "    for j in range(3):\n",
    "        # j == 2\n",
    "        mask = proximity[:,date] < .1\n",
    "        \n",
    "        if j == 0:\n",
    "            mask = proximity[:,date] > .25\n",
    "        \n",
    "        elif j == 1:\n",
    "            mask = (proximity[:,date] <= .25) & (proximity[:,date] > .1)\n",
    "            \n",
    "        axes[j,i].plot(\n",
    "                np.arange(-len(proximity[0])//2,len(proximity[0])//2),\n",
    "                np.mean(s[mask,:,i], axis=0)\n",
    "            , lw=.5, c='black')\n",
    "        axes[j,i].axvline(0, c='red', lw=1)\n",
    "        axes[j,i].set_ylim([0,1])\n",
    "        \n",
    "    axes[0,i].set_title(so_data.ACTIONS[i])\n",
    "    \n",
    "axes[0,0].set_ylabel('Steerers?')\n",
    "axes[1,0].set_ylabel('Unknown?')\n",
    "axes[2,0].set_ylabel('Non-Steerers?')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Notes:\n",
    "    \n",
    "- Different populations have different responses to the badge in the proximity of the badge.\n",
    "    \n",
    "- The population that starts with the lowest count of actions (in the 5 week period) has the biggest deviance from 0 in their response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def test(model, loss_fn, get_latent_par=[]):\n",
    "    latent_pars = {}\n",
    "    latent_pars['steered'] = []\n",
    "    latent_pars['not_steered'] = []\n",
    "    with torch.set_grad_enabled(False):\n",
    "        validation_loss = 0\n",
    "        for val_in, kernel_data, val_out, val_prox, badge_date in test_loader:\n",
    "            # Transfer to GPU\n",
    "            val_in, kernel_data, val_out, val_prox, badge_date = val_in.to(device), \\\n",
    "                            kernel_data.to(device), val_out.to(device), val_prox.to(device), badge_date.to(device)\n",
    "            # Model computations\n",
    "            # Model computations\n",
    "            recon_batch, latent_loss = model(val_in, kernel_data=kernel_data, dob=badge_date, prox_to_badge=val_prox)\n",
    "\n",
    "            loss = loss_fn(recon_batch, val_out, latent_loss)\n",
    "            validation_loss += loss.item()\n",
    "            mu = model.get_z(val_in, kernel_data=kernel_data, dob=badge_date, prox_to_badge=val_prox)\n",
    "\n",
    "            for user_prox, user_mu in zip(val_prox.detach().numpy(), mu.detach().numpy()):\n",
    "                if np.max(user_prox) > .70:\n",
    "                    latent_pars['steered'].append(user_mu[-1])\n",
    "                elif np.max(user_prox) < .1:\n",
    "                    latent_pars['not_steered'].append(user_mu[-1])\n",
    "            for p in get_latent_par:\n",
    "                if p not in latent_pars:\n",
    "                    latent_pars[p] = []\n",
    "                latent_pars[p] += [float(mu_.numpy()) for mu_ in mu[:,p]]\n",
    "        print('Average Test loss: {:.4f}'.format(validation_loss/len(valid_loader.dataset)))\n",
    "    return latent_pars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "dset_shape = dset_train.__getitem__(0)[0].size()\n",
    "params = {\n",
    "    'device': device,\n",
    "    'proximity_to_badge': True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def plot_kernel(dset, model, dset_shape, device, ax=None, title=\"\"):\n",
    "    \n",
    "    val_in, kernel_data, val_out, val_prox, badge_date = dset.__getitem__(0)\n",
    "    print(dset_shape)\n",
    "    val_in, kernel_data, val_out, val_prox, badge_date = val_in.reshape(-1,dset_shape[0],dset_shape[1]).to(device), \\\n",
    "                        kernel_data.reshape(-1,window_len*2).to(device), \\\n",
    "                        val_out.reshape(-1,window_len*2).to(device),     \\\n",
    "                        val_prox.reshape(-1,dset_shape[0]).to(device),    \\\n",
    "                        badge_date.reshape(-1,).to(device)\n",
    "    \n",
    "    if ax == None:\n",
    "        fig, ax = plt.subplots(1,1, figsize=(15,5)) \n",
    "        \n",
    "    recon_batch, latent_loss = model(val_in, kernel_data=kernel_data, dob=badge_date, prox_to_badge=val_prox)\n",
    "    mu = model.get_z(val_in, kernel_data=kernel_data, dob=badge_date, prox_to_badge=val_prox)\n",
    "    k = model.kernel(mu, val_in, kernel_data=kernel_data)\n",
    "    for k_ in k:\n",
    "#         ax.plot(np.arange(-5*7, -1), k_.detach().numpy()[:5*7-1], alpha=1, c='black')\n",
    "#         ax.plot(np.arange(1, 5*7)  , k_.detach().numpy()[5*7+1:], alpha=1, c='black')\n",
    "        ax.plot(np.arange(-5*7, 5*7), k_.detach().numpy(), alpha=1, c='black')\n",
    "\n",
    "    ax.axvline(x=0, lw=.5, ls='--', color='black')\n",
    "    ax.axhline(y=0, lw=.5, ls='--', color='black')\n",
    "    ax.set_ylim([-5,5])\n",
    "    title = model.__class__ if len(title)==0 else title\n",
    "    ax.set_title(title)\n",
    "    \n",
    "    ax.set_xlabel('Days before/after badge')\n",
    "    ax.set_ylabel('Log-odds change acting probability')\n",
    "        \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<hr />\n",
    "\n",
    "<hr />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Method \n",
    "\n",
    "Compare and contrast the models, investigate the functional form of the steering kernel and relax modeling assumptions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Baseline (model 1)\n",
    "Model assumptions:\n",
    "    \n",
    "(1) Every user has their own \"base distribution\".\n",
    "\n",
    "(2) Base distribution does not change between weeks of interaction.\n",
    "\n",
    "![img3](images/img3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "model_base = models.BaselineVAE(dset_shape[0]*dset_shape[1], window_len*2, **params)\n",
    "PATH = '../models/baseline.pt'\n",
    "model_base.load_state_dict(torch.load(PATH, map_location=device))\n",
    "model = model_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "loss_fn = lambda x1,x2,x3: models.BCE_loss_function(x1,x2,x3, data_shape=dset_shape, act_choice=5)\n",
    "_ = test(model_base, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.badge_bump_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_kernel(dset_train, model, dset_shape, device)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Linear parameter (model 2)\n",
    "\n",
    "Model assumptions:\n",
    "    \n",
    "(1) Every user has their own \"base distribution\".\n",
    "\n",
    "(2) Base distribution does not change between weeks of interaction.\n",
    "\n",
    "(3) All users experience a linear strictly positive change in probability of acting as they approach the badge boundary. Thereafter they experience a non-positive change in probability in acting. \n",
    "\n",
    "![img1](images/img1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "model_lin = models.LinearParametricVAE(dset_shape[0]*dset_shape[1], window_len*2, **params)\n",
    "PATH = '../models/linear.pt'\n",
    "model_lin.load_state_dict(torch.load(PATH, map_location=device))\n",
    "model = model_lin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plot_kernel(dset_train, model, dset_shape, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "_ = test(model, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.badge_bump_param"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Personalised Linear (model 3)\n",
    "Model assumptions - same as Linear but:\n",
    "    \n",
    "1) A user-specific steering parameter $\\in (0,1)$ that controls the effect of the deviance from normal acting.\n",
    "\n",
    "![img2](images/img2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "model_per_lin = models.LinearParametricPlusSteerParamVAE(dset_shape[0]*dset_shape[1], window_len*2, **params)\n",
    "PATH = '../models/personalised_linear.pt'\n",
    "model_per_lin.load_state_dict(torch.load(PATH, map_location=device))\n",
    "model = model_per_lin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plot_kernel(dset_train, model, dset_shape, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "ladent_dim = test(model, loss_fn, get_latent_par=[19])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "sigmoid = lambda x: np.exp(x)/(1+np.exp(x))\n",
    "w = model.steer_weight[0].detach().numpy()\n",
    "\n",
    "plt.figure(figsize=(15,3))\n",
    "plt.hist(w*ladent_dim[19], label='entire population', bins=50, alpha=.5, color='grey')\n",
    "plt.hist(w*ladent_dim['not_steered'], label='not steered', alpha=.25, color='red', bins=30)\n",
    "plt.hist(w*ladent_dim['steered'], label='steered', alpha=.25, color='green', bins=30)\n",
    "plt.legend(loc='best')\n",
    "plt.title('Histogram of the latent space that controls the steering param')\n",
    "plt.xlabel(\"$\\sigma^{-1}$\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(15,3))\n",
    "plt.hist(sigmoid(w*ladent_dim[19]), label='entire population', bins=30, alpha=.5, color='grey')\n",
    "plt.hist(sigmoid(w*ladent_dim['not_steered']), label='not steered', alpha=.25, color='red', bins=20)\n",
    "plt.hist(sigmoid(w*ladent_dim['steered']), label='steered', alpha=.25, color='green', bins=20)\n",
    "plt.legend(loc='best')\n",
    "plt.xlim([0,1])\n",
    "plt.title('Histogram of $\\sigma(steering\\ param)$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.badge_bump_param"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Fully parameterised (model 4)\n",
    "\n",
    "Model assumptions:\n",
    "    \n",
    "\n",
    "(1) Every user has their own \"base distribution\".\n",
    "\n",
    "(2) Base distribution does not change between weeks of interaction.\n",
    "\n",
    "(3) All users experience a non-negative change in probability of acting before the badge is achieved and a non-positive change in probability of acting before the badge is achieved.\n",
    "\n",
    "![img1](images/img1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "model_fp = models.FullParameterisedVAE(dset_shape[0]*dset_shape[1], window_len*2, **params)\n",
    "PATH = '../models/full_parameterised.pt'\n",
    "model_fp.load_state_dict(torch.load(PATH, map_location=device))\n",
    "model = model_fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plot_kernel(dset_train, model, dset_shape, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "_ = test(model, loss_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Fully parameterised, personal param (model 5)\n",
    "Model assumptions - same as full parameterised but:\n",
    "    \n",
    "1) A user-specific steering parameter $\\in (0,1)$ that controls the effect of the deviance from normal acting.\n",
    "\n",
    "![img2](images/img2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "model_per_fp = models.FullParameterisedPlusSteerParamVAE(dset_shape[0]*dset_shape[1], window_len*2, **params)\n",
    "PATH = '../models/full_personalised_parameterised.pt'\n",
    "model_per_fp.load_state_dict(torch.load(PATH, map_location=device))\n",
    "model = model_per_fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plot_kernel(dset_train, model, dset_shape, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "ladent_dim = test(model, loss_fn, get_latent_par=[19])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "w = model.steer_weight[0].detach().numpy()\n",
    "\n",
    "plt.figure(figsize=(15,3))\n",
    "plt.hist(w*ladent_dim[19], label='entire population', bins=50, alpha=.5, color='grey')\n",
    "plt.hist(w*ladent_dim['not_steered'], label='not steered', alpha=.25, color='red', bins=30)\n",
    "plt.hist(w*ladent_dim['steered'], label='steered', alpha=.25, color='green', bins=30)\n",
    "plt.legend(loc='best')\n",
    "plt.title('Histogram of the latent space that controls the steering param')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add a Flow to Latent Dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_per_fp_flow = models.FullParameterisedPlusSteerPlusNormParamVAE(\n",
    "                                dset_shape[0]*dset_shape[1], window_len*2, **params)\n",
    "PATH = '../models/full_personalised_parameterised_plus_flow.pt'\n",
    "model_per_fp_flow.load_state_dict(torch.load(PATH, map_location=device))\n",
    "model = model_per_fp_flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_kernel(dset_train, model, dset_shape, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ladent_dim = test(model, loss_fn, get_latent_par=[19])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = model.steer_weight[0].detach().numpy()\n",
    "\n",
    "plt.figure(figsize=(15,3))\n",
    "plt.hist(w*ladent_dim[19], label='entire population', bins=50, alpha=.5, color='grey')\n",
    "plt.hist(w*ladent_dim['not_steered'], label='not steered', alpha=.25, color='red', bins=30)\n",
    "plt.hist(w*ladent_dim['steered'], label='steered', alpha=.25, color='green', bins=30)\n",
    "plt.legend(loc='best')\n",
    "plt.title('Histogram of the latent space that controls the steering param')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Compare the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# compare kernels\n",
    "fig, axes = plt.subplots(2,2,figsize=(15,10))\n",
    "axes = axes.flatten()\n",
    "mdls = [model_lin, model_per_lin, model_fp, model_per_fp]\n",
    "title = ['Linear', 'Linear with personalised', 'Full parameterised', 'Full parameterised with personalised']\n",
    "for i, m in enumerate(mdls):\n",
    "    plot_kernel(dset_train, m, dset_shape, device, ax=axes[i], title=title[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# compare loss\n",
    "print(\"Baseline: \\t\\t\", end='')\n",
    "ladent_dim = test(model_base, loss_fn, get_latent_par=[19])\n",
    "print(\"Linear: \\t\\t\", end='')\n",
    "ladent_dim = test(model_lin, loss_fn, get_latent_par=[19])\n",
    "print(\"Linear + Personalised: \\t\", end='')\n",
    "ladent_dim = test(model_per_lin, loss_fn, get_latent_par=[19])\n",
    "print(\"Full P: \\t\\t\", end='')\n",
    "ladent_dim = test(model_fp, loss_fn, get_latent_par=[19])\n",
    "print(\"Full P + Personalised: \\t\", end='')\n",
    "ladent_dim = test(model_per_fp, loss_fn, get_latent_par=[19])\n",
    "print(\"Full P + Personalised + flow: \\t\", end='')\n",
    "ladent_dim = test(model_per_fp_flow, loss_fn, get_latent_par=[19])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Next Steps\n",
    "\n",
    "## Study the trajectories of the inferences from Full-parameterised model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "latent_pars = {}\n",
    "latent_pars['steered'] = []\n",
    "latent_pars['not_steered'] = []\n",
    "latent_pars['unknown'] = []\n",
    "model = model_per_fp_flow\n",
    "w = model.steer_weight[0].detach().numpy()\n",
    "\n",
    "with torch.set_grad_enabled(False):\n",
    "    validation_loss = 0\n",
    "    for val_in, kernel_data, val_out, val_prox, badge_date in train_loader:\n",
    "        # Transfer to GPU\n",
    "        val_in, kernel_data, val_out, val_prox, badge_date = val_in.to(device), \\\n",
    "                        kernel_data.to(device), val_out.to(device), val_prox.to(device), badge_date.to(device)\n",
    "        # Model computations\n",
    "        # Model computations\n",
    "        recon_batch, latent_loss = model(val_in, kernel_data=kernel_data, dob=badge_date, prox_to_badge=val_prox)\n",
    "\n",
    "        loss = loss_fn(recon_batch, val_out, latent_loss)\n",
    "        validation_loss += loss.item()\n",
    "        \n",
    "        mu = model.get_z(val_in, kernel_data=kernel_data, dob=badge_date, prox_to_badge=val_prox)\n",
    "        \n",
    "        for user_out, user_mu in zip(val_out.detach().numpy(), mu.detach().numpy()):\n",
    "            if w*user_mu[-1] > .5:\n",
    "                latent_pars['steered'].append(user_out)\n",
    "            elif w*user_mu[-1] < -.5:\n",
    "                latent_pars['not_steered'].append(user_out)\n",
    "            else:\n",
    "                latent_pars['unknown'].append(user_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "trajs = np.array(latent_pars['steered'])\n",
    "trajs2 = np.array(latent_pars['not_steered'])\n",
    "trajs3 = np.array(latent_pars['unknown'])\n",
    "\n",
    "plt.figure(figsize=(15,4))\n",
    "plt.plot(np.mean(trajs, axis=0),  label='steered')\n",
    "plt.plot(np.mean(trajs2, axis=0), label='not_steered')\n",
    "plt.plot(np.mean(trajs3, axis=0), label='unknown')\n",
    "plt.title('95 percentile number of votes across time for the groups with different latent parameter thresholds')\n",
    "plt.legend(loc='best')\n",
    "plt.axhline(y=.4, c='black', ls='--', lw=.5)\n",
    "plt.ylim([0,1])\n",
    "plt.ylabel('Probability of acting')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigation of model accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mdl_name in ['model_base', 'model_lin', 'model_per_lin', 'model_fp', 'model_per_fp']:\n",
    "    accs = []\n",
    "    model = eval(mdl_name)\n",
    "    for val_in, kernel_data, val_out, val_prox, badge_date in test_loader:\n",
    "        val_in, kernel_data, val_out, val_prox, badge_date = val_in.to(device), \\\n",
    "                                kernel_data.to(device), val_out.to(device), val_prox.to(device), badge_date.to(device)\n",
    "        # Model computations\n",
    "        # Model computations\n",
    "        recon_batch, latent_loss = model(val_in, kernel_data=kernel_data, dob=badge_date, prox_to_badge=val_prox)\n",
    "        for pred, true in zip(recon_batch.detach().numpy(), val_out.detach().numpy()):\n",
    "#             accs.append(-(np.sum(true*np.log(pred) + (1-true)*np.log(1-pred))))\n",
    "            accs.append((np.sum(true == (pred > .5)))/(2*5*7))\n",
    "    print(mdl_name, np.mean(accs))"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
